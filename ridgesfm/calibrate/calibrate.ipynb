{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration for RidgeSfM\n",
    "\n",
    "Based on https://nikatsanka.github.io/camera-calibration-using-opencv-and-python.html\n",
    "\n",
    "Using your mobile phone camera, create a video of the chessboard pattern.\n",
    "The video should be taken in landscape mode.\n",
    "The phone should move about to view the pattern from different angles; see for example calibrate.3gp.\n",
    "\n",
    "![a](pattern-8x8.png)\n",
    "\n",
    "The code below will find your camera's intrinsic parameters, and prepare your videos for RidgeSfM\n",
    "Then run\n",
    "```\n",
    "python ridgesfm.py scenes=calibrate/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set calibration_file to the name of the chessboard video.\n",
    "# List your RidgeSfM input files in video_files\n",
    "\n",
    "#Video of the 8x8 chessboard (mp4, 3gp or any other format)\n",
    "calibration_file='calibrate.mp4' \n",
    "\n",
    "#Video of a room, with the same zoom settings as for the calibration video.\n",
    "video_files=['room.mp4']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 77 frames for calibration\n",
      "Number of images used for calibration:  77\n",
      "Camera intrinsics\n",
      "tensor([[667.0068,   0.0000, 324.9735],\n",
      "        [  0.0000, 667.6848, 239.3123],\n",
      "        [  0.0000,   0.0000,   1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as TTF\n",
    "import torch, PIL.Image, glob, os, shutil, yaml, numpy as np, cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "if os.path.exists('calibration_images'):\n",
    "    shutil.rmtree('calibration_images/')\n",
    "os.makedirs('calibration_images',exist_ok=False)\n",
    "os.system(f'ffmpeg  -i {calibration_file} -vf \"setpts=0.25*PTS\" calibration_images/image-%07d.png')\n",
    "images=glob.glob('calibration_images/image*png')\n",
    "for x in images:\n",
    "    img=PIL.Image.open(x)\n",
    "    if img.size[0]/img.size[1]>=640/480:\n",
    "        img=TTF.resize(img,480)\n",
    "    else:\n",
    "        img=TTF.resize(img,640)\n",
    "    img=TTF.center_crop(img,(480,640))\n",
    "    assert img.size==(640,480)\n",
    "    img.save(x[:-3]+'png')\n",
    "print('Extracted', len(images), 'frames for calibration')\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "objp = np.zeros((7*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:7].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "for fname in images:  # Here, 10 can be changed to whatever number you like to choose\n",
    "    img = cv2.imread(fname) # Capture frame-by-frame\n",
    "    #print(images[im_i])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,7), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)   # Certainly, every loop objp is the same, in 3D.\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "print(\"Number of images used for calibration: \", len(objpoints))\n",
    "\n",
    "# calibration\n",
    "camera_intrinsics = torch.tensor(cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)[1]).float()\n",
    "\n",
    "print('Camera intrinsics')\n",
    "print(camera_intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-process room.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 752/752 [00:52<00:00, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: python ridgesfm.py scenes=calibrate/ scene.n=0 scene.frameskip=1\n",
      "run: python ridgesfm.py scenes=calibrate/ scene.n=0 scene.frameskip=3\n",
      "run: python ridgesfm.py scenes=calibrate/ scene.n=0 scene.frameskip=10\n",
      "run: python ridgesfm.py scenes=calibrate/ scene.n=0 scene.frameskip=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pre-process videos for RidgeSfM\n",
    "\n",
    "for ctr, x in enumerate(video_files):\n",
    "    print('Pre-process',x)\n",
    "    d=f'{os.getcwd()}/{ctr:06d}_images'\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "    os.makedirs(d,exist_ok=False)\n",
    "    os.system(f'ffmpeg  -i {x} {d}/image-%07d.png')\n",
    "    files=sorted(glob.glob(f'{d}/image*'))\n",
    "    for y in tqdm(files):\n",
    "        img=PIL.Image.open(y)\n",
    "        if img.size[0]/img.size[1]>=640/480:\n",
    "            img=TTF.resize(img,480)\n",
    "        else:\n",
    "            img=TTF.resize(img,640)\n",
    "        img=TTF.center_crop(img,(480,640))\n",
    "        assert img.size==(640,480)\n",
    "        img.save(y)\n",
    "\n",
    "    for frameskip in [1,3,10,30]:\n",
    "        s={'color': files[::frameskip],\n",
    "           'intrinsic': camera_intrinsics,\n",
    "           'pose': torch.stack([torch.eye(4) for _ in files]),\n",
    "           'H': 480,\n",
    "           'W': 640,\n",
    "           'crop': (0,0)\n",
    "        }\n",
    "        torch.save(s,f'{d}/frameskip={frameskip}-{ctr:06d}.pth')\n",
    "        print(f'run: python ridgesfm.py scenes=calibrate/ scene.n={ctr} scene.frameskip={frameskip}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
